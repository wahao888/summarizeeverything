import asyncio
import base64
import json
import websockets
import pyaudio
import requests
import numpy as np
import tkinter as tk
import datetime
import threading
from dotenv import load_dotenv
import os
import ssl
import certifi
from opencc import OpenCC  # ç°¡é«”â†’ç¹é«”è½‰æ›

# è®€å– .env æª”æ¡ˆä¸­çš„ç’°å¢ƒè®Šæ•¸
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY_TRANSCRIBE")
TEXT_LOG_FILE = "transcript_log.txt"

# åˆå§‹åŒ– opencc è½‰æ›å™¨
cc = OpenCC("s2t")

def get_client_secret():
    url = "https://api.openai.com/v1/realtime/transcription_sessions"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
        "OpenAI-Beta": "assistants=v2"
    }
    payload = {
        "input_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "gpt-4o-transcribe",
            "prompt": ""
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,  # èª¿æ•´é–€æª»å€¼
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500  # ç¸®çŸ­éœé»˜æ™‚é–“
        },
        "input_audio_noise_reduction": {
            "type": "near_field"
        }
    }
    resp = requests.post(url, headers=headers, json=payload, verify=certifi.where())
    if resp.status_code != 200:
        raise Exception(f"API è«‹æ±‚å¤±æ•—: {resp.status_code} - {resp.text}")
    return resp.json()["client_secret"]["value"]

class SubtitleWindow:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("ğŸ¤ èªéŸ³è½‰æ–‡å­—å­—å¹•")
        self.root.attributes('-topmost', True)
        self.root.geometry("600x150+50+50")  # èª¿é«˜è¦–çª—é«˜åº¦
        self.root.configure(bg="black")

        self.label = tk.Label(
            self.root,
            text="",
            font=("Helvetica", 16),
            fg="lime",
            bg="black",
            justify="left",   # ğŸ†• æ–‡å­—é å·¦
            anchor="nw",      # ğŸ†• ç”±å·¦ä¸Šé–‹å§‹é¡¯ç¤º
            wraplength=580
        )
        self.label.pack(expand=True, fill="both")

        self.full_text = ""  # ğŸ†• ç”¨ä¾†ç´¯ç©æ‰€æœ‰æ–‡å­—

    def update_text(self, text):
        # ğŸ†• ç´¯ç©ä¸¦ç”¨ after æ’åˆ°ä¸»ç·’æ›´æ–° GUI
        self.full_text += text
        # è‹¥è¦æ›è¡Œï¼Œå¯åœ¨ text å‰å¾Œè‡ªè¡ŒåŠ  "\n"
        self.root.after(0, lambda: self.label.config(text=self.full_text))

    def run(self):
        self.root.mainloop()

def save_text_log(text):
    try:
        with open(TEXT_LOG_FILE, "a", encoding="utf-8") as f:
            timestamp = datetime.datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
            f.write(f"{timestamp} {text}\n")
    except Exception as e:
        print(f"å„²å­˜æ–‡å­—è¨˜éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

async def transcribe_realtime(update_gui_callback):
    client_secret = get_client_secret()

    uri = "wss://api.openai.com/v1/realtime"
    headers = [
        ("Authorization", f"Bearer {client_secret}"),
        ("OpenAI-Beta", "realtime=v1")
    ]
    ssl_ctx = ssl.create_default_context(cafile=certifi.where())

    print("ğŸ”„ æ­£åœ¨å»ºç«‹ WebSocket é€£ç·š...")
    async with websockets.connect(uri, extra_headers=headers, ssl=ssl_ctx) as ws:
        print("âœ… WebSocket é€£ç·šæˆåŠŸ")

        await ws.send(json.dumps({
            "type": "transcription_session.update",
            "session": {
                "input_audio_transcription": {
                    "model": "gpt-4o-transcribe",
                    "prompt": ""
                },
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.5,  # èª¿æ•´é–€æª»å€¼
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 500  # ç¸®çŸ­éœé»˜æ™‚é–“
                },
                "input_audio_noise_reduction": {
                    "type": "near_field"
                },
                "include": []
            }
        }))
        print("âœ… åˆå§‹åŒ–è¨­å®šç™¼é€æˆåŠŸ")

        RATE, CHUNK = 16000, 1024
        pa = pyaudio.PyAudio()
        stream = pa.open(format=pyaudio.paInt16, channels=1, rate=RATE, input=True, frames_per_buffer=CHUNK)
        print("ğŸ™ï¸ éŒ„éŸ³ä¸­... Ctrl+C åœæ­¢")

        async def read_audio():
            while True:
                data = stream.read(CHUNK, exception_on_overflow=False)
                b64 = base64.b64encode(data).decode("utf-8")
                await ws.send(json.dumps({"type": "input_audio_buffer.append", "audio": b64}))
                await asyncio.sleep(CHUNK / RATE)

        async def receive_text():
            async for msg in ws:
                resp = json.loads(msg)
                t = resp.get("type")
                if t == "conversation.item.input_audio_transcription.delta":
                    delta = resp.get("delta", "")
                    if delta:
                        trad = cc.convert(delta)
                        print(f"ğŸ”¤ éƒ¨åˆ†è½‰éŒ„ï¼ˆç¹é«”ï¼‰: {trad}")
                        update_gui_callback(trad)
                        save_text_log(trad)
                elif t == "conversation.item.input_audio_transcription.completed":
                    txt = resp.get("transcript", "")
                    if txt:
                        trad_full = cc.convert(txt)
                        print(f"ğŸ æœ€çµ‚è½‰éŒ„ï¼ˆç¹é«”ï¼‰: {trad_full}")
                        update_gui_callback(trad_full)
                        save_text_log(trad_full)
                elif t == "error":
                    print(f"âŒ éŒ¯èª¤: {resp.get('error')}")

        await asyncio.gather(read_audio(), receive_text())

def main():
    win = SubtitleWindow()
    threading.Thread(target=lambda: asyncio.run(transcribe_realtime(win.update_text)), daemon=True).start()
    win.run()

if __name__ == "__main__":
    main()
